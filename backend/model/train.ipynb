{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras.utils.np_utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Administrator\\Desktop\\sudoku_solver\\backend\\model\\train.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Administrator/Desktop/sudoku_solver/backend/model/train.ipynb#W0sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mimage\u001b[39;00m \u001b[39mimport\u001b[39;00m ImageDataGenerator\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Administrator/Desktop/sudoku_solver/backend/model/train.ipynb#W0sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mimage\u001b[39;00m \u001b[39mimport\u001b[39;00m ImageDataGenerator, load_img\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Administrator/Desktop/sudoku_solver/backend/model/train.ipynb#W0sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnp_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m to_categorical\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Administrator/Desktop/sudoku_solver/backend/model/train.ipynb#W0sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Administrator/Desktop/sudoku_solver/backend/model/train.ipynb#W0sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m Activation, Dropout, Dense, Flatten, BatchNormalization, Conv2D, MaxPooling2D\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras.utils.np_utils'"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os, random\n",
    "import cv2\n",
    "from glob import glob\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dropout, Dense, Flatten, BatchNormalization, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from pathlib import Path\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Dataponits =  10160\n"
     ]
    }
   ],
   "source": [
    "data = os.listdir(\"../data/Digits\" )\n",
    "data_X = []     \n",
    "data_y = []  \n",
    "data_classes = len(data)\n",
    "for i in range (0, data_classes):\n",
    "    data_list = os.listdir(\"../data/Digits\" +\"/\"+str(i))\n",
    "    for j in data_list:\n",
    "        pic = cv2.imread(\"../data/Digits\" +\"/\"+str(i)+\"/\"+j)\n",
    "        pic = cv2.resize(pic, (32, 32))\n",
    "        data_X.append(pic)\n",
    "        data_y.append(i)\n",
    "if len(data_X) == len(data_y) :\n",
    "    print(\"Total Dataponits = \",len(data_X))\n",
    "data_X = np.array(data_X)\n",
    "data_y = np.array(data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Shape =  (7721, 32, 32, 3)\n",
      "Validation Set Shape =  (1931, 32, 32, 3)\n",
      "Test Set Shape =  (508, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(data_X,data_y,test_size=0.05)\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(train_X,train_y,test_size=0.2)\n",
    "print(\"Training Set Shape = \",train_X.shape)\n",
    "print(\"Validation Set Shape = \",valid_X.shape)\n",
    "print(\"Test Set Shape = \",test_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prep(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) #making image grayscale\n",
    "    img = cv2.equalizeHist(img) #Histogram equalization to enhance contrast\n",
    "    img = img/255 #normalizing\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.array(list(map(Prep, train_X)))\n",
    "test_X = np.array(list(map(Prep, test_X)))\n",
    "valid_X= np.array(list(map(Prep, valid_X)))\n",
    "#Reshaping the images\n",
    "train_X = train_X.reshape(train_X.shape[0], train_X.shape[1], train_X.shape[2],1)\n",
    "test_X = test_X.reshape(test_X.shape[0], test_X.shape[1], test_X.shape[2],1)\n",
    "valid_X = valid_X.reshape(valid_X.shape[0], valid_X.shape[1], valid_X.shape[2],1)\n",
    "#Augmentation\n",
    "datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, zoom_range=0.2, shear_range=0.1, rotation_range=10)\n",
    "datagen.fit(train_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = to_categorical(train_y, data_classes)\n",
    "test_y = to_categorical(test_y, data_classes)\n",
    "valid_y = to_categorical(valid_y, data_classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
